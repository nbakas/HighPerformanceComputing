{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "accelerator": "GPU",
    "colab": {
      "provenance": [],
      "toc_visible": true,
      "gpuType": "T4"
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "source": [
        "\n",
        "# GPU - Accelerated Linear Algebra in Python\n",
        "\n",
        "Wednesday, 29 May 2024\n",
        "\n",
        "https://eurocc.cyi.ac.cy/intermediate-level-programming-for-hpc-programming-using-python-training-event-2024/\n",
        "\n",
        "*   CUDA (Compute Unified Device Architecture) is a parallel computing platform and\n",
        "application programming interface (API) model created by NVIDIA that allows developers to use NVIDIA GPUs for general-purpose processing.\n",
        "*   CuPy allows Python users to achieve GPU acceleration with minimal code changes, leveraging familiar NumPy-like syntax."
      ],
      "metadata": {
        "id": "xib8Ml7JQO_d"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from psutil import virtual_memory\n",
        "ram_gb = virtual_memory().total / 1e9\n",
        "print('Your runtime has {:.1f} gigabytes of available RAM\\n'.format(ram_gb))\n",
        "\n",
        "gpu_info = !nvidia-smi\n",
        "gpu_info = '\\n'.join(gpu_info)\n",
        "print(gpu_info)"
      ],
      "metadata": {
        "id": "GJ1Tz3A1q7fd",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "c770dad7-0e60-43fa-c051-ca47b9981f87"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Your runtime has 13.6 gigabytes of available RAM\n",
            "\n",
            "Wed May 29 10:26:27 2024       \n",
            "+---------------------------------------------------------------------------------------+\n",
            "| NVIDIA-SMI 535.104.05             Driver Version: 535.104.05   CUDA Version: 12.2     |\n",
            "|-----------------------------------------+----------------------+----------------------+\n",
            "| GPU  Name                 Persistence-M | Bus-Id        Disp.A | Volatile Uncorr. ECC |\n",
            "| Fan  Temp   Perf          Pwr:Usage/Cap |         Memory-Usage | GPU-Util  Compute M. |\n",
            "|                                         |                      |               MIG M. |\n",
            "|=========================================+======================+======================|\n",
            "|   0  Tesla T4                       Off | 00000000:00:04.0 Off |                    0 |\n",
            "| N/A   70C    P0              31W /  70W |    103MiB / 15360MiB |      0%      Default |\n",
            "|                                         |                      |                  N/A |\n",
            "+-----------------------------------------+----------------------+----------------------+\n",
            "                                                                                         \n",
            "+---------------------------------------------------------------------------------------+\n",
            "| Processes:                                                                            |\n",
            "|  GPU   GI   CI        PID   Type   Process name                            GPU Memory |\n",
            "|        ID   ID                                                             Usage      |\n",
            "|=======================================================================================|\n",
            "+---------------------------------------------------------------------------------------+\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "### NVIDIA GPU Information\n",
        "\n",
        "- **GPU Details:** The system uses an NVIDIA Tesla T4 GPU, which is not running in persistence mode and is currently utilizing a minimal 9W of its 70W power capacity.\n",
        "- **Memory and Utilization:** The GPU has 15.36GB of memory available, with 0% utilization at the moment, indicating no active processes using the GPU.\n",
        "- **System Information:** The system is operating with NVIDIA driver version 535.104.05 and CUDA version 12.2, which are essential for running GPU-accelerated computations."
      ],
      "metadata": {
        "id": "OVMxDwXvPaiY"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Import Libraries"
      ],
      "metadata": {
        "id": "gqu57tccw2Cf"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import numpy as np\n",
        "import time"
      ],
      "metadata": {
        "id": "RPbta1eqRKvM"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import os\n",
        "# Get the number of available processors\n",
        "num_processors = os.cpu_count()\n",
        "# Print the number of processors\n",
        "print(f\"Number of available processors: {num_processors}\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "I2bubqExRePQ",
        "outputId": "f25e0f17-aa03-4c14-e596-441431ac1ca7"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Number of available processors: 2\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import cupy as cp\n",
        "\n",
        "# Ensure the CUDA device is properly synchronized before fetching memory info\n",
        "cp.cuda.runtime.deviceSynchronize()\n",
        "device = cp.cuda.Device(0)  # Select the first GPU device\n",
        "\n",
        "# Retrieve the total and free memory available on the GPU\n",
        "free_memory, total_memory = cp.cuda.runtime.memGetInfo()\n",
        "\n",
        "# Convert memory information from bytes to gigabytes for clarity\n",
        "total_memory_gb = total_memory / (1024 ** 3)\n",
        "free_memory_gb = free_memory / (1024 ** 3)\n",
        "\n",
        "# Print both the total and free GPU memory to verify the values\n",
        "print(f\"Total GPU Memory: {total_memory_gb:.2f} GB\")\n",
        "print(f\"Free GPU Memory: {free_memory_gb:.2f} GB\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "JwFkRuuBfEZ9",
        "outputId": "5ab3f22f-771d-4f36-a166-4d944d5a67cc"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Total GPU Memory: 14.75 GB\n",
            "Free GPU Memory: 14.65 GB\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Matrix Multiplication"
      ],
      "metadata": {
        "id": "Gcm0e1A0w6By"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "**Input:** $N \\in \\mathbb{Z}^+$  \n",
        "*Dimension of the matrices*\n",
        "\n",
        "- $A \\gets \\text{random matrix of size } N \\times N$\n",
        "- $B \\gets \\text{random matrix of size } N \\times N$\n",
        "- $T \\gets 0$  \n",
        "   *Initialize total time*\n",
        "\n",
        "**For** $i \\in \\{1, 2, \\dots, 10\\}$:\n",
        "   - $t_{\\text{start}} \\gets \\text{current time}$\n",
        "   - $C \\gets A \\times B$  \n",
        "      *Matrix multiplication*\n",
        "   - $t_{\\text{end}} \\gets \\text{current time}$\n",
        "   - $T \\gets T + (t_{\\text{end}} - t_{\\text{start}})$\n",
        "\n",
        "\n",
        "$\\text{average time} \\gets T / 10$\n"
      ],
      "metadata": {
        "id": "o5QFU3KSUs_w"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Matrix size\n",
        "N = 2_000"
      ],
      "metadata": {
        "id": "lw4DnF1GRMKI"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Create matrices using NumPy\n",
        "A_np = np.random.rand(N, N)\n",
        "B_np = np.random.rand(N, N)\n",
        "np.dot(A_np, B_np) # avoid initial overheads\n",
        "\n",
        "# Measure NumPy time for matrix multiplication\n",
        "start_time_np = time.time()\n",
        "for i in range(10):\n",
        "  C_np = np.dot(A_np, B_np)\n",
        "  print(\"Benchmark:\",i+1)\n",
        "numpy_time = (time.time() - start_time_np)/10\n",
        "\n",
        "print(f\"NumPy Time: {numpy_time:.6f} seconds\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "FSLaF2rTP1le",
        "outputId": "8694921a-7a2e-43c9-d322-98c5b1355fcf"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Benchmark: 1\n",
            "Benchmark: 2\n",
            "Benchmark: 3\n",
            "Benchmark: 4\n",
            "Benchmark: 5\n",
            "Benchmark: 6\n",
            "Benchmark: 7\n",
            "Benchmark: 8\n",
            "Benchmark: 9\n",
            "Benchmark: 10\n",
            "NumPy Time: 0.287114 seconds\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Convert NumPy arrays to CuPy arrays\n",
        "A_cp = cp.asarray(A_np)\n",
        "B_cp = cp.asarray(B_np)\n",
        "cp.dot(A_cp, B_cp) # avoid initial overheads\n",
        "\n",
        "# Measure CuPy time for matrix multiplication\n",
        "start_time_cp = time.time()\n",
        "for i in range(10):\n",
        "  C_cp = cp.dot(A_cp, B_cp)\n",
        "  print(\"Benchmark:\",i+1)\n",
        "cupy_time = (time.time() - start_time_cp)/10\n",
        "\n",
        "print(f\"CuPy Time: {cupy_time:.6f} seconds\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "MCL05aPvRRBS",
        "outputId": "a95fb4b6-8660-4c25-82e3-1d7b4c42a975"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Benchmark: 1\n",
            "Benchmark: 2\n",
            "Benchmark: 3\n",
            "Benchmark: 4\n",
            "Benchmark: 5\n",
            "Benchmark: 6\n",
            "Benchmark: 7\n",
            "Benchmark: 8\n",
            "Benchmark: 9\n",
            "Benchmark: 10\n",
            "CuPy Time: 0.000837 seconds\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "print(f\"NumPy/CuPy Time: {numpy_time/cupy_time:.6f}\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "wWSaZDuUVSwC",
        "outputId": "acd09cc5-e308-4cbb-c09d-b9a28c4385f8"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "NumPy/CuPy Time: 342.845125\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "...run this with $N=2,000$..."
      ],
      "metadata": {
        "id": "bX4mGRecRVrA"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "- **Optimized Libraries**: CuPy utilizes CUDA and highly optimized GPU libraries (like cuBLAS) for mathematical operations, leading to more efficient execution compared to CPU-bound operations in NumPy.\n",
        "- **Multiple threads** simultaneously process different portions of data, performing partial reductions in parallel.\n",
        "- **Memory Bandwidth**: GPUs have higher memory bandwidth compared to CPUs, enabling faster data transfer rates and reducing the time spent on reading and writing large matrices."
      ],
      "metadata": {
        "id": "6zSZpsrCTaSm"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Element-wise addition"
      ],
      "metadata": {
        "id": "qfN7kGOQw9LP"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Size of the vectors\n",
        "N = 1_000"
      ],
      "metadata": {
        "id": "aPdSBf9sVugW"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Number of iterations for averaging the results\n",
        "num_iterations = 10\n",
        "\n",
        "# Create arrays with NumPy and CuPy\n",
        "A_np = np.random.rand(N)\n",
        "B_np = np.random.rand(N)\n",
        "A_cp = cp.asarray(A_np)\n",
        "B_cp = cp.asarray(B_np)\n",
        "\n",
        "# Initialize timers\n",
        "numpy_total_time = 0\n",
        "cupy_total_time = 0\n",
        "\n",
        "# Warm up to ensure GPU is initialized\n",
        "# cp.add(cp.asarray(np.random.rand(N)), cp.asarray(np.random.rand(N)))\n",
        "\n",
        "for _ in range(num_iterations):\n",
        "    # Time NumPy operation\n",
        "    start_np = time.time()\n",
        "    C_np = A_np + B_np\n",
        "    numpy_time = time.time() - start_np\n",
        "    numpy_total_time += numpy_time\n",
        "\n",
        "    # Time CuPy operation\n",
        "    start_cp = time.time()\n",
        "    C_cp = A_cp + B_cp\n",
        "    cp.cuda.Device().synchronize()  # Ensure all operations are complete\n",
        "    cupy_time = time.time() - start_cp\n",
        "    cupy_total_time += cupy_time\n",
        "\n",
        "# Compute average times\n",
        "average_numpy_time = numpy_total_time / num_iterations\n",
        "average_cupy_time = cupy_total_time / num_iterations\n",
        "\n",
        "print(f\"Average NumPy Element-wise Addition Time: {average_numpy_time:.6f} seconds\")\n",
        "print(f\"Average CuPy Element-wise Addition Time: {average_cupy_time:.6f} seconds\")\n",
        "print(f\"NumPy/CuPy Time: {average_numpy_time/average_cupy_time:.6f}\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "8p4zwUyfxEl5",
        "outputId": "d366b92b-3833-4259-9365-1d2b730a0a50"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Average NumPy Element-wise Addition Time: 0.000009 seconds\n",
            "Average CuPy Element-wise Addition Time: 0.000189 seconds\n",
            "NumPy/CuPy Time: 0.046845\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "...run again for $N=1000$..."
      ],
      "metadata": {
        "id": "2Q64jRVpbdZd"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Why NumPy is Faster for Small $N$\n",
        "\n",
        "- **GPU Overhead:** Initializing and synchronizing the GPU incurs overhead that can outweigh the benefits of parallel processing for small data sizes.\n",
        "- **Memory Transfer:** Transferring data between CPU and GPU memory introduces latency that is significant when dealing with small arrays, making CPU operations faster.\n",
        "\n",
        "*To fully leverage GPU performance, send large batches of data to minimize overhead and maximize parallel processing efficiency.*"
      ],
      "metadata": {
        "id": "hiK2cHnNUR7G"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "N=10\n",
        "A_np = np.random.rand(N)\n",
        "A_cp = cp.asarray(A_np)\n",
        "cp.asarray(A_cp)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "VltdtjHm8oN2",
        "outputId": "eba4b227-4437-49b2-e8c6-b22d5ef71942"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "array([0.57825197, 0.03214955, 0.08726671, 0.3660074 , 0.14379972,\n",
              "       0.50778563, 0.61231925, 0.42992299, 0.02151465, 0.7966884 ])"
            ]
          },
          "metadata": {},
          "execution_count": 11
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "k1IdYwKU_Yd2"
      },
      "source": [
        "# SolveBak"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "**The SolveBak Algorithm**\n",
        "\n",
        "**Input**: $\\mathbf{X}$, $\\mathbf{y}$\n",
        "\n",
        "**Output**: $\\mathbf{a}$\n",
        "\n",
        "1. Initialize $\\mathbf{a} = a_{j \\in \\{1,2,\\dots,n\\}} = \\mathbf{0}_n$ (initial guess)\n",
        "2. Compute $\\mathbf{e} = \\mathbf{y} - \\mathbf{X} \\times \\mathbf{a}$\n",
        "\n",
        "3. For $i \\in \\{1,2,\\dots,N\\}$:\n",
        "   1. For $j \\in \\{1,2,\\dots,n\\}$:\n",
        "      1. $da = \\frac{\\langle \\mathbf{X}_j, \\mathbf{e} \\rangle}{\\langle \\mathbf{X}_j, \\mathbf{X}_j \\rangle}$\n",
        "      2. Update $\\mathbf{e} \\leftarrow \\mathbf{e} - \\mathbf{X}_j \\times da$\n",
        "      3. Update $a_j \\leftarrow a_j + da$\n",
        "\n",
        "4. Return $\\mathbf{a}$ such that $\\mathbf{X} \\times \\mathbf{a} = \\mathbf{y}$\n"
      ],
      "metadata": {
        "id": "s3t5Y-iXRvuR"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "view more on https://arxiv.org/pdf/2104.12570"
      ],
      "metadata": {
        "id": "1x_A4wPklo3u"
      }
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "rc7VHIWQXy83"
      },
      "source": [
        "---\n",
        "## Initialize variables\n",
        "---"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "obs=100_000\n",
        "vars=1_000\n",
        "ITERS = 10"
      ],
      "metadata": {
        "id": "p3sdD9MiiwQt"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "r7r4N5W-X2Dj"
      },
      "source": [
        "## SolveBak with *NumPy*"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "5zyVF0nlXwxA",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "5b425899-a189-4239-fa17-34a11c74c3b7"
      },
      "source": [
        "x=np.random.rand(obs,vars)-1/2\n",
        "a=np.random.rand(vars)-1/2\n",
        "y=np.dot(x,a)\n",
        "\n",
        "x_x=np.sum(x*x,axis=0)\n",
        "aa=np.zeros(vars)\n",
        "e=np.copy(y)\n",
        "t1=time.time()\n",
        "for i in range(ITERS):\n",
        "    for j in range(vars):\n",
        "        da=np.dot(x[:,j],e)/x_x[j]\n",
        "        e-=da*x[:,j]\n",
        "        aa[j]+=da\n",
        "t2=time.time()\n",
        "\n",
        "numpy_time = t2-t1\n",
        "print(f\"NumPy time: {numpy_time:.6f}- Error: {np.mean(np.abs(a-aa)):.3E}\")"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "NumPy time: 13.085524- Error: 2.592E-14\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "## SolveBak with *CuPy*"
      ],
      "metadata": {
        "id": "V5eMND7rjAU6"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "x=cp.random.rand(obs,vars)-1/2\n",
        "a=cp.random.rand(vars)-1/2\n",
        "y=cp.dot(x,a)\n",
        "\n",
        "aa = cp.zeros(vars)\n",
        "x_x=cp.sum(x*x,axis=0)\n",
        "e = cp.copy(y)\n",
        "t1 = time.time()\n",
        "for i in range(ITERS):\n",
        "    for j in range(vars):\n",
        "        da = cp.dot(x[:, j], e) / x_x[j]\n",
        "        e -= da * x[:, j]\n",
        "        aa[j] += da\n",
        "t2 = time.time()\n",
        "\n",
        "cupy_time = t2-t1\n",
        "print(f\"CuPy time: {cupy_time:.6f} - Error: {cp.mean(cp.abs(cp.asarray(a)-aa)):.3E}\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "M_oSmbrnjCfF",
        "outputId": "7cf8b311-2989-4e5b-ae36-aad6ae9fc2ae"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "CuPy time: 2.783537 - Error: 2.990E-14\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "print(f\"NumPy/CuPy Time: {numpy_time/cupy_time:.6f}\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "5L1PvKxfgPW4",
        "outputId": "c804268c-e6c8-4a43-b24e-f6434de03e1c"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "NumPy/CuPy Time: 4.701041\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "G2oEtadVcfUl"
      },
      "source": [
        "# SolveBak with batches"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "**The Parallel HPSCDP Solver**\n",
        "\n",
        "**Input**: $\\mathbf{X}$, $\\mathbf{y}$\n",
        "\n",
        "**Output**: $\\mathbf{a}$\n",
        "\n",
        "1. Initialize $\\mathbf{a} = \\mathbf{0}_n$ (or an initial guess).\n",
        "2. Compute $\\mathbf{e} = \\mathbf{y} - \\mathbf{X} \\times \\mathbf{a}$.\n",
        "\n",
        "3. For $i \\in \\{1,2,\\dots,N\\}$:\n",
        "   1. Set $\\mathbf{a_{\\text{prev}}} \\leftarrow \\mathbf{a}$.\n",
        "   2. For $j \\in \\{1, \\text{thr}+1, 2\\text{thr}+1, \\dots, n-\\text{thr}+1\\}$:\n",
        "      1. For $k \\in \\{j, j+1, \\dots, j+\\text{thr}-1\\}$ do in parallel:\n",
        "         1. Update $a_k \\leftarrow a_k + \\frac{\\langle \\mathbf{X}_k, \\mathbf{e} \\rangle}{\\langle \\mathbf{X}_k, \\mathbf{X}_k \\rangle}$.\n",
        "      2. Update $\\mathbf{e} \\leftarrow \\mathbf{e} - \\mathbf{X}_{jj} \\times de$,\n",
        "      .\n",
        "\n",
        "4. Return $\\mathbf{a}$ such that $\\mathbf{X} \\times \\mathbf{a} = \\mathbf{y}$."
      ],
      "metadata": {
        "id": "zSO6KlFajddc"
      }
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "m8gcqwUPcMn2"
      },
      "source": [
        "---\n",
        "## Initialize variables\n",
        "---"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "obs=100_000\n",
        "vars=1_000\n",
        "ITERS = 10\n",
        "BATCH = 100"
      ],
      "metadata": {
        "id": "XdToWDQRcG7W"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## SolveBak with *NumPy* in BATCHES"
      ],
      "metadata": {
        "id": "OzuYaN_9tydR"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "x=np.random.rand(obs,vars)-1/2\n",
        "a=np.random.rand(vars)-1/2\n",
        "y=np.dot(x,a)\n",
        "\n",
        "x_x=np.sum(x*x,axis=0)\n",
        "aa=np.zeros(vars)\n",
        "e=np.copy(y)\n",
        "t1=time.time()\n",
        "for i in range(ITERS):\n",
        "    for j in range(0,vars,BATCH):\n",
        "        # here we apply dot product for matrices instead of vectors\n",
        "        da = np.dot(x[:, j:j+BATCH].T, e) / x_x[j:j+BATCH]\n",
        "        e -= np.sum(da * x[:, j:j+BATCH], axis=1)\n",
        "        aa[j:j+BATCH] += da\n",
        "\n",
        "t2=time.time()\n",
        "numpy_time = t2-t1\n",
        "print(f\"NumPy time: {numpy_time:.6f}- Error: {np.mean(np.abs(a-aa)):.3E}\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "30Zqm2WDtU1X",
        "outputId": "66e38e47-90cf-4cad-889d-d057f724dd6c"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "NumPy time: 0.005257- Error: 9.576E-04\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "## SolveBak with *CuPy* in BATCHES"
      ],
      "metadata": {
        "id": "HLGlMOIrt6Of"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "x=cp.random.rand(obs,vars)-1/2\n",
        "a=cp.random.rand(vars)-1/2\n",
        "y=cp.dot(x,a)\n",
        "\n",
        "aa = cp.zeros(vars)\n",
        "x_x=cp.sum(x*x,axis=0)\n",
        "e = cp.copy(y)\n",
        "t1 = time.time()\n",
        "for i in range(ITERS):\n",
        "    for j in range(0,vars,BATCH):\n",
        "        da = cp.dot(x[:, j:j+BATCH].T, e) / x_x[j:j+BATCH]\n",
        "        e -= cp.sum(da * x[:, j:j+BATCH], axis=1)\n",
        "        aa[j:j+BATCH] += da\n",
        "t2=time.time()\n",
        "\n",
        "cupy_time = t2-t1\n",
        "print(f\"CuPy time: {cupy_time:.6f} - Error: {cp.mean(cp.abs(cp.asarray(a)-aa)):.3E}\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "ji2Kb__-pk8s",
        "outputId": "0b32b19b-0b14-4361-b0b7-53c6d5260a14"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "CuPy time: 0.179903 - Error: 8.580E-04\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "print(f\"NumPy/CuPy Time: {numpy_time/cupy_time:.6f}\")"
      ],
      "metadata": {
        "id": "-j77w1GOvruT",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "e83c22de-6d89-4257-f168-c5aafbb81394"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "NumPy/CuPy Time: 0.029219\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "...run again with small obs..."
      ],
      "metadata": {
        "id": "1dAQBEOZgWLD"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "CuPy is faster than NumPy when using the second algorithm with batches:\n",
        "\n",
        "1. **Parallel Batch Processing:** CuPy leverages the GPU's parallel processing capabilities, allowing multiple batches to be processed concurrently. This significantly speeds up the reduction operations within each batch, compared to the sequential processing on a CPU.\n",
        "\n",
        "2. **Optimized Memory Usage:** GPUs have higher memory bandwidth and can handle large data transfers more efficiently.\n",
        "\n",
        "3. **Batch Size Optimization**: Larger batch sizes can be handled more efficiently on GPUs, fully utilizing their massive parallel architecture and reducing overhead.\n",
        "\n",
        "*Batch size should be less than the available GPU RAM to avoid memory overflow; use MPI for larger data sizes to distribute computation across multiple GPUs or nodes.*"
      ],
      "metadata": {
        "id": "BaManx4VYb0T"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Artificial Neural Networks"
      ],
      "metadata": {
        "id": "cSfzuCrQi4_X"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "$$y_i \\cong \\sum\\limits_{k=1}^{N}{{{v}_{k}}}\\sigma \\left( \\sum\\limits_{j=1}^{n}{{{w}_{jk}}{{x}_{ij}}}+{{b}_{k}} \\right)+{{b}_{0}}$$"
      ],
      "metadata": {
        "id": "5KJNHqrQnQZM"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "https://link.springer.com/content/pdf/10.1007/s00477-023-02407-2.pdf"
      ],
      "metadata": {
        "id": "3UJO9Wlcn2jP"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import datetime\n",
        "import numpy as np\n",
        "import time\n",
        "import matplotlib.pyplot as plt"
      ],
      "metadata": {
        "id": "NpviCS3vW-wH"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## With NumPy"
      ],
      "metadata": {
        "id": "4hTGxGJTo_cK"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "obs = 100_000\n",
        "vars = 10"
      ],
      "metadata": {
        "id": "BB9nrKNpaHOr"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Prepare the training and testing sets"
      ],
      "metadata": {
        "id": "lGmbtv7Ran7_"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "x=np.random.rand(obs,vars)-1/2\n",
        "y = np.sin(np.sum(x,axis=1))/2\n",
        "\n",
        "xt=np.random.rand(obs,vars)-1/2\n",
        "yt = np.sin(np.sum(xt,axis=1))/2"
      ],
      "metadata": {
        "id": "Q3ceyE_IXEL4"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Define the number of neurons"
      ],
      "metadata": {
        "id": "0kzhC47HawZq"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "neurons = 1_000"
      ],
      "metadata": {
        "id": "SynrO-dXW1Bs"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "i_train = x.shape[0]\n",
        "layer1 = np.zeros((i_train, neurons))\n",
        "w_all = []\n",
        "i_err = []"
      ],
      "metadata": {
        "id": "5f3xs9n9ZLtk"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Size of internal neurons' batch"
      ],
      "metadata": {
        "id": "L6fLWeOaa7cq"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "n_train_internal = x.shape[0]//neurons\n",
        "n_train_internal"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "9UolD23Qn8PD",
        "outputId": "75295672-0645-475c-f564-8591f4af090c"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "100"
            ]
          },
          "metadata": {},
          "execution_count": 51
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "$$\\mathbf{X}_k := (x_{ijk})_{i \\in [m_k], j \\in [n]}$$\n",
        "\n",
        "$$\\sigma \\odot \\Big(\\big(\\mathbf{X}_k \\Big|\\mathbf{1}\\big) \\times \\mathbf{w}_k\\Big) = \\mathbf{y}_k$$\n",
        "\n",
        "$$\\big(\\mathbf{X}_k \\Big| \\mathbf{1}\\big) \\times \\mathbf{w}_k = \\sigma^{-1} \\odot (\\mathbf{y}_k )$$"
      ],
      "metadata": {
        "id": "Zeo4z1AQnh25"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "yy = np.arctanh(y)"
      ],
      "metadata": {
        "id": "EBpLJll9quN_"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Compute internal neurons weights"
      ],
      "metadata": {
        "id": "Ho-TLiTsbMIy"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "print(\"Computing internal neurons' weights...\")\n",
        "t1=time.time()\n",
        "for i in range(neurons):\n",
        "    ii = np.random.permutation(x.shape[0])[:n_train_internal]\n",
        "    try:\n",
        "        aa = np.linalg.lstsq(x[ii],yy[ii], rcond=None)[0]\n",
        "        w_all.append(aa)\n",
        "        if i in range(0,neurons,neurons//10):\n",
        "            sdt = datetime.datetime.now().strftime('%H:%M:%S.%f')[:-3]\n",
        "            print(sdt,\"Computing weights for neuron\",i,\"of\",neurons)\n",
        "    except Exception as ex:\n",
        "        i_err.append(i)\n",
        "        print(\"Error in neuron \", i, \":\", ex)\n",
        "\n",
        "t2=time.time()\n",
        "numpy_time_inner = t2-t1\n",
        "print(f\"NumPy time: {numpy_time_inner:.6f}\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "vq-ZnQz7WQSA",
        "outputId": "fbc2d19e-cf8a-41cd-f13a-149941dfac84"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Computing internal neurons' weights...\n",
            "11:09:03.365 Computing weights for neuron 0 of 1000\n",
            "11:09:03.538 Computing weights for neuron 100 of 1000\n",
            "11:09:03.719 Computing weights for neuron 200 of 1000\n",
            "11:09:03.899 Computing weights for neuron 300 of 1000\n",
            "11:09:04.085 Computing weights for neuron 400 of 1000\n",
            "11:09:04.277 Computing weights for neuron 500 of 1000\n",
            "11:09:04.460 Computing weights for neuron 600 of 1000\n",
            "11:09:04.642 Computing weights for neuron 700 of 1000\n",
            "11:09:04.820 Computing weights for neuron 800 of 1000\n",
            "11:09:05.001 Computing weights for neuron 900 of 1000\n",
            "NumPy time: 1.827874\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Formulate outer layer"
      ],
      "metadata": {
        "id": "_VbtbKsQbQzb"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "w_all = np.array(w_all)\n",
        "w_all.shape\n",
        "sdt = datetime.datetime.now().strftime('%H:%M:%S.%f')[:-3]\n",
        "print(sdt,\"Formulating Layers\")\n",
        "layer1 = np.tanh(np.dot(x, w_all.T))"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "uqKf2cIqWufW",
        "outputId": "66a3255e-9994-4151-a54d-ac019d451bc6"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "11:09:07.586 Formulating Layers\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "$$\\mathbf{\\hat{X}} := \\bigg[ \\sigma \\odot \\Big(\\big(\\mathbf{X} \\Big| \\mathbf{1}\\big)\\times \\mathbf{w} \\Big) \\bigg| \\mathbf{1}\\bigg]$$\n",
        "\n",
        "$$ \\mathbf{\\hat{X}} \\times \\mathbf{v} = \\mathbf{y}$$"
      ],
      "metadata": {
        "id": "9xRcOxaVoRTU"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Solve for outter layer's weights"
      ],
      "metadata": {
        "id": "RuJhqFWpbWCA"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "t1=time.time()\n",
        "# V = np.linalg.lstsq(layer1,y,rcond=-1)[0]\n",
        "V = np.linalg.solve(layer1.T@layer1,layer1.T@y)\n",
        "t2=time.time()\n",
        "numpy_time_outer = t2-t1\n",
        "print(f\"NumPy time: {numpy_time_outer:.6f}\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "S3LWIx4jXT1f",
        "outputId": "9c83afb9-c832-46bf-9ba5-96beb1069f4f"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "NumPy time: 3.085749\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Check accuracy"
      ],
      "metadata": {
        "id": "UHU0X1aLbcv0"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "pred = np.dot(layer1,V)\n",
        "np.corrcoef(pred,y)[0,1]"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "H5y4SRe5Xej2",
        "outputId": "78a9b134-9563-458c-de68-d5ea5945e8c0"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "0.9999978851393453"
            ]
          },
          "metadata": {},
          "execution_count": 56
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "layer1t = np.tanh(np.dot(xt, w_all.T))\n",
        "predt = np.dot(layer1t,V)\n",
        "np.corrcoef(predt,yt)[0,1]"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "sWebHoLdlxeu",
        "outputId": "7fea6da3-4399-44e7-c6b9-bce38eabebcd"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "0.9999978173657291"
            ]
          },
          "metadata": {},
          "execution_count": 57
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "plt.scatter(predt,yt)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 448
        },
        "collapsed": true,
        "id": "4AZxYryMdx8b",
        "outputId": "c0c446cb-7be7-4b75-e73b-2dfd5956a339"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<matplotlib.collections.PathCollection at 0x7bacbf906c50>"
            ]
          },
          "metadata": {},
          "execution_count": 58
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<Figure size 640x480 with 1 Axes>"
            ],
            "image/png": "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\n"
          },
          "metadata": {}
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "## With CuPy"
      ],
      "metadata": {
        "id": "2JIXBV_WXvcS"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import cupy as cp"
      ],
      "metadata": {
        "id": "zJZ-PJwcmFbn"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Transfer data to GPU"
      ],
      "metadata": {
        "id": "qnRh8flRboBx"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "x = cp.array(x)\n",
        "y = cp.array(y)\n",
        "xt = cp.array(xt)\n",
        "yt = cp.array(yt)"
      ],
      "metadata": {
        "id": "ppRT3dkrXxDN"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Initialize variables"
      ],
      "metadata": {
        "id": "K51XrYuRbsw1"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "layer1 = cp.zeros((i_train, neurons))\n",
        "w_all = []\n",
        "i_err = []\n",
        "ii_all = []"
      ],
      "metadata": {
        "id": "U7SUMCwqZEVm"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "yy = cp.arctanh(y)"
      ],
      "metadata": {
        "id": "UA6ZnmqUq2Jq"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Compute internal neurons' weights"
      ],
      "metadata": {
        "id": "-93VioR7bxVK"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "t1=time.time()\n",
        "for i in range(neurons):\n",
        "    ii = np.random.permutation(x.shape[0])[:n_train_internal]\n",
        "    ii_all.append(ii)\n",
        "    try:\n",
        "        aa = cp.linalg.lstsq(x[ii],yy[ii], rcond=None)[0]\n",
        "        w_all.append(aa)\n",
        "        if i in range(0,neurons,neurons//10):\n",
        "            sdt = datetime.datetime.now().strftime('%H:%M:%S.%f')[:-3]\n",
        "            print(sdt,\"Computing weights for neuron\",i,\"of\",neurons)\n",
        "    except Exception as ex:\n",
        "        i_err.append(i)\n",
        "        print(\"Error in neuron \", i, \":\", ex)\n",
        "\n",
        "t2=time.time()\n",
        "cupy_time_inner = t2-t1\n",
        "print(f\"CuPy time: {cupy_time_inner:.6f}\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "FLC19MK4ZG2e",
        "outputId": "fbb739e8-0095-4142-b81b-5bb409deb6fc"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "11:09:59.873 Computing weights for neuron 0 of 1000\n",
            "11:10:00.502 Computing weights for neuron 100 of 1000\n",
            "11:10:01.118 Computing weights for neuron 200 of 1000\n",
            "11:10:01.734 Computing weights for neuron 300 of 1000\n",
            "11:10:02.708 Computing weights for neuron 400 of 1000\n",
            "11:10:03.720 Computing weights for neuron 500 of 1000\n",
            "11:10:04.306 Computing weights for neuron 600 of 1000\n",
            "11:10:04.778 Computing weights for neuron 700 of 1000\n",
            "11:10:05.249 Computing weights for neuron 800 of 1000\n",
            "11:10:05.739 Computing weights for neuron 900 of 1000\n",
            "CuPy time: 17.150124\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "w_all = cp.array(w_all)\n",
        "w_all.shape\n",
        "sdt = datetime.datetime.now().strftime('%H:%M:%S.%f')[:-3]\n",
        "print(sdt,\"Formulating Layers\")\n",
        "layer1 = cp.tanh(cp.dot(x, w_all.T))"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "bkrLRPmzZdUl",
        "outputId": "bbd85f44-8efe-4589-f82f-7de2ad581747"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "11:10:13.617 Formulating Layers\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Solve for outter layer's weights"
      ],
      "metadata": {
        "id": "mj-gq13HcRCh"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "t1=time.time()\n",
        "# V = cp.linalg.lstsq(layer1,y,rcond=-1)[0]\n",
        "V = cp.linalg.solve(layer1.T@layer1,layer1.T@y)\n",
        "t2=time.time()\n",
        "cupy_time_outer = t2-t1\n",
        "print(f\"CuPy time: {cupy_time_outer:.6f}\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "EyIU4e7iZob8",
        "outputId": "2015c791-6841-41d6-f7c4-bd12de854ca2"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "CuPy time: 1.269419\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Check the accuracy"
      ],
      "metadata": {
        "id": "dMdVfMTlcUS7"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "pred = cp.dot(layer1,V)\n",
        "cp.corrcoef(pred,y)[0,1]"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "vMmnujxLZp4L",
        "outputId": "7c50024c-bdf4-4f09-91f7-c6981e764c1d"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "array(0.9999495)"
            ]
          },
          "metadata": {},
          "execution_count": 66
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "layer1t = cp.tanh(cp.dot(xt, w_all.T))\n",
        "predt = cp.dot(layer1t,V)\n",
        "cp.corrcoef(predt,yt)[0,1]"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "WdMi6tKWZxDO",
        "outputId": "628d4da9-f059-4bc3-d8f3-9818e04ad02d"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "array(0.99994792)"
            ]
          },
          "metadata": {},
          "execution_count": 67
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Comparison"
      ],
      "metadata": {
        "id": "jS-_e1vnqDTm"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "print(f\"NumPy/CuPy Time - Inner Layer: {numpy_time_inner/cupy_time_inner:.6f}\")"
      ],
      "metadata": {
        "id": "Pko2WF88met6",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "38f3373e-3295-4b62-f6ae-7915dcdedcb8"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "NumPy/CuPy Time - Inner Layer: 0.106581\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "print(f\"NumPy/CuPy Time - Output Layer: {numpy_time_outer/cupy_time_outer:.6f}\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "a55clruhqMpu",
        "outputId": "2a1e658b-fa04-42c0-af68-51c880e0c01f"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "NumPy/CuPy Time - Output Layer: 2.430836\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Conclusions\n",
        "\n",
        "- **Matrix Multiplication Performance:** CuPy significantly outperforms NumPy in matrix multiplication, leveraging GPU parallelism for faster computations.\n",
        "- **Element-wise Operations:** For large arrays, CuPy is much faster than NumPy due to efficient parallel processing and higher memory bandwidth of GPUs.\n",
        "- **Batch Processing Efficiency:** CuPy handles large batches more effectively, fully utilizing GPU capabilities and reducing overhead, but batch sizes must be within available GPU RAM to avoid memory overflow.\n",
        "- **Optimization Strategy:** For handling larger data sizes exceeding GPU memory, use MPI to distribute computations across multiple GPUs or nodes for better performance and efficiency."
      ],
      "metadata": {
        "id": "bjoaYPMBcsef"
      }
    }
  ]
}