{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "xib8Ml7JQO_d"
      },
      "source": [
        "\n",
        "# GPU - Accelerated Linear Algebra in Python\n",
        "\n",
        "*   CUDA (Compute Unified Device Architecture) is a parallel computing platform and\n",
        "application programming interface (API) model created by NVIDIA that allows developers to use NVIDIA GPUs for general-purpose processing.\n",
        "*   CuPy allows Python users to achieve GPU acceleration with minimal code changes, leveraging familiar NumPy-like syntax."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "GJ1Tz3A1q7fd",
        "outputId": "c770dad7-0e60-43fa-c051-ca47b9981f87"
      },
      "outputs": [],
      "source": [
        "from psutil import virtual_memory\n",
        "ram_gb = virtual_memory().total / 1e9\n",
        "print('Your runtime has {:.1f} gigabytes of available RAM\\n'.format(ram_gb))\n",
        "\n",
        "gpu_info = !nvidia-smi\n",
        "gpu_info = '\\n'.join(gpu_info)\n",
        "print(gpu_info)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "OVMxDwXvPaiY"
      },
      "source": [
        "### NVIDIA GPU Information\n",
        "\n",
        "- **GPU Details:** The system uses an NVIDIA Tesla T4 GPU, which is not running in persistence mode and is currently utilizing a minimal 9W of its 70W power capacity.\n",
        "- **Memory and Utilization:** The GPU has 15.36GB of memory available, with 0% utilization at the moment, indicating no active processes using the GPU.\n",
        "- **System Information:** The system is operating with NVIDIA driver version 535.104.05 and CUDA version 12.2, which are essential for running GPU-accelerated computations."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "gqu57tccw2Cf"
      },
      "source": [
        "# Import Libraries"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "RPbta1eqRKvM"
      },
      "outputs": [],
      "source": [
        "import numpy as np\n",
        "import time"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "I2bubqExRePQ",
        "outputId": "f25e0f17-aa03-4c14-e596-441431ac1ca7"
      },
      "outputs": [],
      "source": [
        "import os\n",
        "# Get the number of available processors\n",
        "num_processors = os.cpu_count()\n",
        "# Print the number of processors\n",
        "print(f\"Number of available processors: {num_processors}\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "JwFkRuuBfEZ9",
        "outputId": "5ab3f22f-771d-4f36-a166-4d944d5a67cc"
      },
      "outputs": [],
      "source": [
        "import cupy as cp\n",
        "\n",
        "# Ensure the CUDA device is properly synchronized before fetching memory info\n",
        "cp.cuda.runtime.deviceSynchronize()\n",
        "device = cp.cuda.Device(0)  # Select the first GPU device\n",
        "\n",
        "# Retrieve the total and free memory available on the GPU\n",
        "free_memory, total_memory = cp.cuda.runtime.memGetInfo()\n",
        "\n",
        "# Convert memory information from bytes to gigabytes for clarity\n",
        "total_memory_gb = total_memory / (1024 ** 3)\n",
        "free_memory_gb = free_memory / (1024 ** 3)\n",
        "\n",
        "# Print both the total and free GPU memory to verify the values\n",
        "print(f\"Total GPU Memory: {total_memory_gb:.2f} GB\")\n",
        "print(f\"Free GPU Memory: {free_memory_gb:.2f} GB\")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Gcm0e1A0w6By"
      },
      "source": [
        "# Matrix Multiplication"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "o5QFU3KSUs_w"
      },
      "source": [
        "**Input:** $N \\in \\mathbb{Z}^+$  \n",
        "*Dimension of the matrices*\n",
        "\n",
        "- $A \\gets \\text{random matrix of size } N \\times N$\n",
        "- $B \\gets \\text{random matrix of size } N \\times N$\n",
        "- $T \\gets 0$  \n",
        "   *Initialize total time*\n",
        "\n",
        "**For** $i \\in \\{1, 2, \\dots, 10\\}$:\n",
        "   - $t_{\\text{start}} \\gets \\text{current time}$\n",
        "   - $C \\gets A \\times B$  \n",
        "      *Matrix multiplication*\n",
        "   - $t_{\\text{end}} \\gets \\text{current time}$\n",
        "   - $T \\gets T + (t_{\\text{end}} - t_{\\text{start}})$\n",
        "\n",
        "\n",
        "$\\text{average time} \\gets T / 10$\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "lw4DnF1GRMKI"
      },
      "outputs": [],
      "source": [
        "# Matrix size\n",
        "N = 2_000"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "FSLaF2rTP1le",
        "outputId": "8694921a-7a2e-43c9-d322-98c5b1355fcf"
      },
      "outputs": [],
      "source": [
        "# Create matrices using NumPy\n",
        "A_np = np.random.rand(N, N)\n",
        "B_np = np.random.rand(N, N)\n",
        "np.dot(A_np, B_np) # avoid initial overheads\n",
        "\n",
        "# Measure NumPy time for matrix multiplication\n",
        "start_time_np = time.time()\n",
        "for i in range(10):\n",
        "  C_np = np.dot(A_np, B_np)\n",
        "  print(\"Benchmark:\",i+1)\n",
        "numpy_time = (time.time() - start_time_np)/10\n",
        "\n",
        "print(f\"NumPy Time: {numpy_time:.6f} seconds\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "MCL05aPvRRBS",
        "outputId": "a95fb4b6-8660-4c25-82e3-1d7b4c42a975"
      },
      "outputs": [],
      "source": [
        "# Convert NumPy arrays to CuPy arrays\n",
        "A_cp = cp.asarray(A_np)\n",
        "B_cp = cp.asarray(B_np)\n",
        "cp.dot(A_cp, B_cp) # avoid initial overheads\n",
        "\n",
        "# Measure CuPy time for matrix multiplication\n",
        "start_time_cp = time.time()\n",
        "for i in range(10):\n",
        "  C_cp = cp.dot(A_cp, B_cp)\n",
        "  print(\"Benchmark:\",i+1)\n",
        "cupy_time = (time.time() - start_time_cp)/10\n",
        "\n",
        "print(f\"CuPy Time: {cupy_time:.6f} seconds\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "wWSaZDuUVSwC",
        "outputId": "acd09cc5-e308-4cbb-c09d-b9a28c4385f8"
      },
      "outputs": [],
      "source": [
        "print(f\"NumPy/CuPy Time: {numpy_time/cupy_time:.6f}\")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "bX4mGRecRVrA"
      },
      "source": [
        "...run this with $N=2,000$..."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "6zSZpsrCTaSm"
      },
      "source": [
        "- **Optimized Libraries**: CuPy utilizes CUDA and highly optimized GPU libraries (like cuBLAS) for mathematical operations, leading to more efficient execution compared to CPU-bound operations in NumPy.\n",
        "- **Multiple threads** simultaneously process different portions of data, performing partial reductions in parallel.\n",
        "- **Memory Bandwidth**: GPUs have higher memory bandwidth compared to CPUs, enabling faster data transfer rates and reducing the time spent on reading and writing large matrices."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "qfN7kGOQw9LP"
      },
      "source": [
        "# Element-wise addition"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "aPdSBf9sVugW"
      },
      "outputs": [],
      "source": [
        "# Size of the vectors\n",
        "N = 1_000"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "8p4zwUyfxEl5",
        "outputId": "d366b92b-3833-4259-9365-1d2b730a0a50"
      },
      "outputs": [],
      "source": [
        "# Number of iterations for averaging the results\n",
        "num_iterations = 10\n",
        "\n",
        "# Create arrays with NumPy and CuPy\n",
        "A_np = np.random.rand(N)\n",
        "B_np = np.random.rand(N)\n",
        "A_cp = cp.asarray(A_np)\n",
        "B_cp = cp.asarray(B_np)\n",
        "\n",
        "# Initialize timers\n",
        "numpy_total_time = 0\n",
        "cupy_total_time = 0\n",
        "\n",
        "# Warm up to ensure GPU is initialized\n",
        "# cp.add(cp.asarray(np.random.rand(N)), cp.asarray(np.random.rand(N)))\n",
        "\n",
        "for _ in range(num_iterations):\n",
        "    # Time NumPy operation\n",
        "    start_np = time.time()\n",
        "    C_np = A_np + B_np\n",
        "    numpy_time = time.time() - start_np\n",
        "    numpy_total_time += numpy_time\n",
        "\n",
        "    # Time CuPy operation\n",
        "    start_cp = time.time()\n",
        "    C_cp = A_cp + B_cp\n",
        "    cp.cuda.Device().synchronize()  # Ensure all operations are complete\n",
        "    cupy_time = time.time() - start_cp\n",
        "    cupy_total_time += cupy_time\n",
        "\n",
        "# Compute average times\n",
        "average_numpy_time = numpy_total_time / num_iterations\n",
        "average_cupy_time = cupy_total_time / num_iterations\n",
        "\n",
        "print(f\"Average NumPy Element-wise Addition Time: {average_numpy_time:.6f} seconds\")\n",
        "print(f\"Average CuPy Element-wise Addition Time: {average_cupy_time:.6f} seconds\")\n",
        "print(f\"NumPy/CuPy Time: {average_numpy_time/average_cupy_time:.6f}\")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "2Q64jRVpbdZd"
      },
      "source": [
        "...run again for $N=1000$..."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "hiK2cHnNUR7G"
      },
      "source": [
        "### Why NumPy is Faster for Small $N$\n",
        "\n",
        "- **GPU Overhead:** Initializing and synchronizing the GPU incurs overhead that can outweigh the benefits of parallel processing for small data sizes.\n",
        "- **Memory Transfer:** Transferring data between CPU and GPU memory introduces latency that is significant when dealing with small arrays, making CPU operations faster.\n",
        "\n",
        "*To fully leverage GPU performance, send large batches of data to minimize overhead and maximize parallel processing efficiency.*"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "VltdtjHm8oN2",
        "outputId": "eba4b227-4437-49b2-e8c6-b22d5ef71942"
      },
      "outputs": [],
      "source": [
        "N=10\n",
        "A_np = np.random.rand(N)\n",
        "A_cp = cp.asarray(A_np)\n",
        "cp.asarray(A_cp)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "k1IdYwKU_Yd2"
      },
      "source": [
        "# SolveBak"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "s3t5Y-iXRvuR"
      },
      "source": [
        "**The SolveBak Algorithm**\n",
        "\n",
        "**Input**: $\\mathbf{X}$, $\\mathbf{y}$\n",
        "\n",
        "**Output**: $\\mathbf{a}$\n",
        "\n",
        "1. Initialize $\\mathbf{a} = a_{j \\in \\{1,2,\\dots,n\\}} = \\mathbf{0}_n$ (initial guess)\n",
        "2. Compute $\\mathbf{e} = \\mathbf{y} - \\mathbf{X} \\times \\mathbf{a}$\n",
        "\n",
        "3. For $i \\in \\{1,2,\\dots,N\\}$:\n",
        "   1. For $j \\in \\{1,2,\\dots,n\\}$:\n",
        "      1. $da = \\frac{\\langle \\mathbf{X}_j, \\mathbf{e} \\rangle}{\\langle \\mathbf{X}_j, \\mathbf{X}_j \\rangle}$\n",
        "      2. Update $\\mathbf{e} \\leftarrow \\mathbf{e} - \\mathbf{X}_j \\times da$\n",
        "      3. Update $a_j \\leftarrow a_j + da$\n",
        "\n",
        "4. Return $\\mathbf{a}$ such that $\\mathbf{X} \\times \\mathbf{a} = \\mathbf{y}$\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "1x_A4wPklo3u"
      },
      "source": [
        "view more on https://arxiv.org/pdf/2104.12570"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "rc7VHIWQXy83"
      },
      "source": [
        "---\n",
        "## Initialize variables\n",
        "---"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "p3sdD9MiiwQt"
      },
      "outputs": [],
      "source": [
        "obs=100_000\n",
        "vars=1_000\n",
        "ITERS = 10"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "r7r4N5W-X2Dj"
      },
      "source": [
        "## SolveBak with *NumPy*"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "5zyVF0nlXwxA",
        "outputId": "5b425899-a189-4239-fa17-34a11c74c3b7"
      },
      "outputs": [],
      "source": [
        "x=np.random.rand(obs,vars)-1/2\n",
        "a=np.random.rand(vars)-1/2\n",
        "y=np.dot(x,a)\n",
        "\n",
        "x_x=np.sum(x*x,axis=0)\n",
        "aa=np.zeros(vars)\n",
        "e=np.copy(y)\n",
        "t1=time.time()\n",
        "for i in range(ITERS):\n",
        "    for j in range(vars):\n",
        "        da=np.dot(x[:,j],e)/x_x[j]\n",
        "        e-=da*x[:,j]\n",
        "        aa[j]+=da\n",
        "t2=time.time()\n",
        "\n",
        "numpy_time = t2-t1\n",
        "print(f\"NumPy time: {numpy_time:.6f}- Error: {np.mean(np.abs(a-aa)):.3E}\")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "V5eMND7rjAU6"
      },
      "source": [
        "## SolveBak with *CuPy*"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "M_oSmbrnjCfF",
        "outputId": "7cf8b311-2989-4e5b-ae36-aad6ae9fc2ae"
      },
      "outputs": [],
      "source": [
        "x=cp.random.rand(obs,vars)-1/2\n",
        "a=cp.random.rand(vars)-1/2\n",
        "y=cp.dot(x,a)\n",
        "\n",
        "aa = cp.zeros(vars)\n",
        "x_x=cp.sum(x*x,axis=0)\n",
        "e = cp.copy(y)\n",
        "t1 = time.time()\n",
        "for i in range(ITERS):\n",
        "    for j in range(vars):\n",
        "        da = cp.dot(x[:, j], e) / x_x[j]\n",
        "        e -= da * x[:, j]\n",
        "        aa[j] += da\n",
        "t2 = time.time()\n",
        "\n",
        "cupy_time = t2-t1\n",
        "print(f\"CuPy time: {cupy_time:.6f} - Error: {cp.mean(cp.abs(cp.asarray(a)-aa)):.3E}\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "5L1PvKxfgPW4",
        "outputId": "c804268c-e6c8-4a43-b24e-f6434de03e1c"
      },
      "outputs": [],
      "source": [
        "print(f\"NumPy/CuPy Time: {numpy_time/cupy_time:.6f}\")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "G2oEtadVcfUl"
      },
      "source": [
        "# SolveBak with batches"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "zSO6KlFajddc"
      },
      "source": [
        "**The Parallel HPSCDP Solver**\n",
        "\n",
        "**Input**: $\\mathbf{X}$, $\\mathbf{y}$\n",
        "\n",
        "**Output**: $\\mathbf{a}$\n",
        "\n",
        "1. Initialize $\\mathbf{a} = \\mathbf{0}_n$ (or an initial guess).\n",
        "2. Compute $\\mathbf{e} = \\mathbf{y} - \\mathbf{X} \\times \\mathbf{a}$.\n",
        "\n",
        "3. For $i \\in \\{1,2,\\dots,N\\}$:\n",
        "   1. Set $\\mathbf{a_{\\text{prev}}} \\leftarrow \\mathbf{a}$.\n",
        "   2. For $j \\in \\{1, \\text{thr}+1, 2\\text{thr}+1, \\dots, n-\\text{thr}+1\\}$:\n",
        "      1. For $k \\in \\{j, j+1, \\dots, j+\\text{thr}-1\\}$ do in parallel:\n",
        "         1. Update $a_k \\leftarrow a_k + \\frac{\\langle \\mathbf{X}_k, \\mathbf{e} \\rangle}{\\langle \\mathbf{X}_k, \\mathbf{X}_k \\rangle}$.\n",
        "      2. Update $\\mathbf{e} \\leftarrow \\mathbf{e} - \\mathbf{X}_{jj} \\times de$,\n",
        "      .\n",
        "\n",
        "4. Return $\\mathbf{a}$ such that $\\mathbf{X} \\times \\mathbf{a} = \\mathbf{y}$."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "m8gcqwUPcMn2"
      },
      "source": [
        "---\n",
        "## Initialize variables\n",
        "---"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "XdToWDQRcG7W"
      },
      "outputs": [],
      "source": [
        "obs=100_000\n",
        "vars=1_000\n",
        "ITERS = 10\n",
        "BATCH = 100"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "OzuYaN_9tydR"
      },
      "source": [
        "## SolveBak with *NumPy* in BATCHES"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "30Zqm2WDtU1X",
        "outputId": "66e38e47-90cf-4cad-889d-d057f724dd6c"
      },
      "outputs": [],
      "source": [
        "x=np.random.rand(obs,vars)-1/2\n",
        "a=np.random.rand(vars)-1/2\n",
        "y=np.dot(x,a)\n",
        "\n",
        "x_x=np.sum(x*x,axis=0)\n",
        "aa=np.zeros(vars)\n",
        "e=np.copy(y)\n",
        "t1=time.time()\n",
        "for i in range(ITERS):\n",
        "    for j in range(0,vars,BATCH):\n",
        "        # here we apply dot product for matrices instead of vectors\n",
        "        da = np.dot(x[:, j:j+BATCH].T, e) / x_x[j:j+BATCH]\n",
        "        e -= np.sum(da * x[:, j:j+BATCH], axis=1)\n",
        "        aa[j:j+BATCH] += da\n",
        "\n",
        "t2=time.time()\n",
        "numpy_time = t2-t1\n",
        "print(f\"NumPy time: {numpy_time:.6f}- Error: {np.mean(np.abs(a-aa)):.3E}\")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "HLGlMOIrt6Of"
      },
      "source": [
        "## SolveBak with *CuPy* in BATCHES"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "ji2Kb__-pk8s",
        "outputId": "0b32b19b-0b14-4361-b0b7-53c6d5260a14"
      },
      "outputs": [],
      "source": [
        "x=cp.random.rand(obs,vars)-1/2\n",
        "a=cp.random.rand(vars)-1/2\n",
        "y=cp.dot(x,a)\n",
        "\n",
        "aa = cp.zeros(vars)\n",
        "x_x=cp.sum(x*x,axis=0)\n",
        "e = cp.copy(y)\n",
        "t1 = time.time()\n",
        "for i in range(ITERS):\n",
        "    for j in range(0,vars,BATCH):\n",
        "        da = cp.dot(x[:, j:j+BATCH].T, e) / x_x[j:j+BATCH]\n",
        "        e -= cp.sum(da * x[:, j:j+BATCH], axis=1)\n",
        "        aa[j:j+BATCH] += da\n",
        "t2=time.time()\n",
        "\n",
        "cupy_time = t2-t1\n",
        "print(f\"CuPy time: {cupy_time:.6f} - Error: {cp.mean(cp.abs(cp.asarray(a)-aa)):.3E}\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "-j77w1GOvruT",
        "outputId": "e83c22de-6d89-4257-f168-c5aafbb81394"
      },
      "outputs": [],
      "source": [
        "print(f\"NumPy/CuPy Time: {numpy_time/cupy_time:.6f}\")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "1dAQBEOZgWLD"
      },
      "source": [
        "...run again with small obs..."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "BaManx4VYb0T"
      },
      "source": [
        "CuPy is faster than NumPy when using the second algorithm with batches:\n",
        "\n",
        "1. **Parallel Batch Processing:** CuPy leverages the GPU's parallel processing capabilities, allowing multiple batches to be processed concurrently. This significantly speeds up the reduction operations within each batch, compared to the sequential processing on a CPU.\n",
        "\n",
        "2. **Optimized Memory Usage:** GPUs have higher memory bandwidth and can handle large data transfers more efficiently.\n",
        "\n",
        "3. **Batch Size Optimization**: Larger batch sizes can be handled more efficiently on GPUs, fully utilizing their massive parallel architecture and reducing overhead.\n",
        "\n",
        "*Batch size should be less than the available GPU RAM to avoid memory overflow; use MPI for larger data sizes to distribute computation across multiple GPUs or nodes.*"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "cSfzuCrQi4_X"
      },
      "source": [
        "# Artificial Neural Networks"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "5KJNHqrQnQZM"
      },
      "source": [
        "$$y_i \\cong \\sum\\limits_{k=1}^{N}{{{v}_{k}}}\\sigma \\left( \\sum\\limits_{j=1}^{n}{{{w}_{jk}}{{x}_{ij}}}+{{b}_{k}} \\right)+{{b}_{0}}$$"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "3UJO9Wlcn2jP"
      },
      "source": [
        "https://link.springer.com/content/pdf/10.1007/s00477-023-02407-2.pdf"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "NpviCS3vW-wH"
      },
      "outputs": [],
      "source": [
        "import datetime\n",
        "import numpy as np\n",
        "import time\n",
        "import matplotlib.pyplot as plt"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "4hTGxGJTo_cK"
      },
      "source": [
        "## With NumPy"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "BB9nrKNpaHOr"
      },
      "outputs": [],
      "source": [
        "obs = 100_000\n",
        "vars = 10"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "lGmbtv7Ran7_"
      },
      "source": [
        "### Prepare the training and testing sets"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "Q3ceyE_IXEL4"
      },
      "outputs": [],
      "source": [
        "x=np.random.rand(obs,vars)-1/2\n",
        "y = np.sin(np.sum(x,axis=1))/2\n",
        "\n",
        "xt=np.random.rand(obs,vars)-1/2\n",
        "yt = np.sin(np.sum(xt,axis=1))/2"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "0kzhC47HawZq"
      },
      "source": [
        "### Define the number of neurons"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "SynrO-dXW1Bs"
      },
      "outputs": [],
      "source": [
        "neurons = 1_000"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "5f3xs9n9ZLtk"
      },
      "outputs": [],
      "source": [
        "i_train = x.shape[0]\n",
        "layer1 = np.zeros((i_train, neurons))\n",
        "w_all = []\n",
        "i_err = []"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "L6fLWeOaa7cq"
      },
      "source": [
        "### Size of internal neurons' batch"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "9UolD23Qn8PD",
        "outputId": "75295672-0645-475c-f564-8591f4af090c"
      },
      "outputs": [],
      "source": [
        "n_train_internal = x.shape[0]//neurons\n",
        "n_train_internal"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Zeo4z1AQnh25"
      },
      "source": [
        "$$\\mathbf{X}_k := (x_{ijk})_{i \\in [m_k], j \\in [n]}$$\n",
        "\n",
        "$$\\sigma \\odot \\Big(\\big(\\mathbf{X}_k \\Big|\\mathbf{1}\\big) \\times \\mathbf{w}_k\\Big) = \\mathbf{y}_k$$\n",
        "\n",
        "$$\\big(\\mathbf{X}_k \\Big| \\mathbf{1}\\big) \\times \\mathbf{w}_k = \\sigma^{-1} \\odot (\\mathbf{y}_k )$$"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "EBpLJll9quN_"
      },
      "outputs": [],
      "source": [
        "yy = np.arctanh(y)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Ho-TLiTsbMIy"
      },
      "source": [
        "### Compute internal neurons weights"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "vq-ZnQz7WQSA",
        "outputId": "fbc2d19e-cf8a-41cd-f13a-149941dfac84"
      },
      "outputs": [],
      "source": [
        "print(\"Computing internal neurons' weights...\")\n",
        "t1=time.time()\n",
        "for i in range(neurons):\n",
        "    ii = np.random.permutation(x.shape[0])[:n_train_internal]\n",
        "    try:\n",
        "        aa = np.linalg.lstsq(x[ii],yy[ii], rcond=None)[0]\n",
        "        w_all.append(aa)\n",
        "        if i in range(0,neurons,neurons//10):\n",
        "            sdt = datetime.datetime.now().strftime('%H:%M:%S.%f')[:-3]\n",
        "            print(sdt,\"Computing weights for neuron\",i,\"of\",neurons)\n",
        "    except Exception as ex:\n",
        "        i_err.append(i)\n",
        "        print(\"Error in neuron \", i, \":\", ex)\n",
        "\n",
        "t2=time.time()\n",
        "numpy_time_inner = t2-t1\n",
        "print(f\"NumPy time: {numpy_time_inner:.6f}\")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "_VbtbKsQbQzb"
      },
      "source": [
        "### Formulate outer layer"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "uqKf2cIqWufW",
        "outputId": "66a3255e-9994-4151-a54d-ac019d451bc6"
      },
      "outputs": [],
      "source": [
        "w_all = np.array(w_all)\n",
        "w_all.shape\n",
        "sdt = datetime.datetime.now().strftime('%H:%M:%S.%f')[:-3]\n",
        "print(sdt,\"Formulating Layers\")\n",
        "layer1 = np.tanh(np.dot(x, w_all.T))"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "9xRcOxaVoRTU"
      },
      "source": [
        "$$\\mathbf{\\hat{X}} := \\bigg[ \\sigma \\odot \\Big(\\big(\\mathbf{X} \\Big| \\mathbf{1}\\big)\\times \\mathbf{w} \\Big) \\bigg| \\mathbf{1}\\bigg]$$\n",
        "\n",
        "$$ \\mathbf{\\hat{X}} \\times \\mathbf{v} = \\mathbf{y}$$"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "RuJhqFWpbWCA"
      },
      "source": [
        "### Solve for outter layer's weights"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "S3LWIx4jXT1f",
        "outputId": "9c83afb9-c832-46bf-9ba5-96beb1069f4f"
      },
      "outputs": [],
      "source": [
        "t1=time.time()\n",
        "# V = np.linalg.lstsq(layer1,y,rcond=-1)[0]\n",
        "V = np.linalg.solve(layer1.T@layer1,layer1.T@y)\n",
        "t2=time.time()\n",
        "numpy_time_outer = t2-t1\n",
        "print(f\"NumPy time: {numpy_time_outer:.6f}\")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "UHU0X1aLbcv0"
      },
      "source": [
        "### Check accuracy"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "H5y4SRe5Xej2",
        "outputId": "78a9b134-9563-458c-de68-d5ea5945e8c0"
      },
      "outputs": [],
      "source": [
        "pred = np.dot(layer1,V)\n",
        "np.corrcoef(pred,y)[0,1]"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "sWebHoLdlxeu",
        "outputId": "7fea6da3-4399-44e7-c6b9-bce38eabebcd"
      },
      "outputs": [],
      "source": [
        "layer1t = np.tanh(np.dot(xt, w_all.T))\n",
        "predt = np.dot(layer1t,V)\n",
        "np.corrcoef(predt,yt)[0,1]"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 448
        },
        "collapsed": true,
        "id": "4AZxYryMdx8b",
        "outputId": "c0c446cb-7be7-4b75-e73b-2dfd5956a339"
      },
      "outputs": [],
      "source": [
        "plt.scatter(predt,yt)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "2JIXBV_WXvcS"
      },
      "source": [
        "## With CuPy"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "zJZ-PJwcmFbn"
      },
      "outputs": [],
      "source": [
        "import cupy as cp"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "qnRh8flRboBx"
      },
      "source": [
        "### Transfer data to GPU"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "ppRT3dkrXxDN"
      },
      "outputs": [],
      "source": [
        "x = cp.array(x)\n",
        "y = cp.array(y)\n",
        "xt = cp.array(xt)\n",
        "yt = cp.array(yt)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "K51XrYuRbsw1"
      },
      "source": [
        "### Initialize variables"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "U7SUMCwqZEVm"
      },
      "outputs": [],
      "source": [
        "layer1 = cp.zeros((i_train, neurons))\n",
        "w_all = []\n",
        "i_err = []\n",
        "ii_all = []"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "UA6ZnmqUq2Jq"
      },
      "outputs": [],
      "source": [
        "yy = cp.arctanh(y)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "-93VioR7bxVK"
      },
      "source": [
        "### Compute internal neurons' weights"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "FLC19MK4ZG2e",
        "outputId": "fbb739e8-0095-4142-b81b-5bb409deb6fc"
      },
      "outputs": [],
      "source": [
        "t1=time.time()\n",
        "for i in range(neurons):\n",
        "    ii = np.random.permutation(x.shape[0])[:n_train_internal]\n",
        "    ii_all.append(ii)\n",
        "    try:\n",
        "        aa = cp.linalg.lstsq(x[ii],yy[ii], rcond=None)[0]\n",
        "        w_all.append(aa)\n",
        "        if i in range(0,neurons,neurons//10):\n",
        "            sdt = datetime.datetime.now().strftime('%H:%M:%S.%f')[:-3]\n",
        "            print(sdt,\"Computing weights for neuron\",i,\"of\",neurons)\n",
        "    except Exception as ex:\n",
        "        i_err.append(i)\n",
        "        print(\"Error in neuron \", i, \":\", ex)\n",
        "\n",
        "t2=time.time()\n",
        "cupy_time_inner = t2-t1\n",
        "print(f\"CuPy time: {cupy_time_inner:.6f}\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "bkrLRPmzZdUl",
        "outputId": "bbd85f44-8efe-4589-f82f-7de2ad581747"
      },
      "outputs": [],
      "source": [
        "w_all = cp.array(w_all)\n",
        "w_all.shape\n",
        "sdt = datetime.datetime.now().strftime('%H:%M:%S.%f')[:-3]\n",
        "print(sdt,\"Formulating Layers\")\n",
        "layer1 = cp.tanh(cp.dot(x, w_all.T))"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "mj-gq13HcRCh"
      },
      "source": [
        "### Solve for outter layer's weights"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "EyIU4e7iZob8",
        "outputId": "2015c791-6841-41d6-f7c4-bd12de854ca2"
      },
      "outputs": [],
      "source": [
        "t1=time.time()\n",
        "# V = cp.linalg.lstsq(layer1,y,rcond=-1)[0]\n",
        "V = cp.linalg.solve(layer1.T@layer1,layer1.T@y)\n",
        "t2=time.time()\n",
        "cupy_time_outer = t2-t1\n",
        "print(f\"CuPy time: {cupy_time_outer:.6f}\")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "dMdVfMTlcUS7"
      },
      "source": [
        "### Check the accuracy"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "vMmnujxLZp4L",
        "outputId": "7c50024c-bdf4-4f09-91f7-c6981e764c1d"
      },
      "outputs": [],
      "source": [
        "pred = cp.dot(layer1,V)\n",
        "cp.corrcoef(pred,y)[0,1]"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "WdMi6tKWZxDO",
        "outputId": "628d4da9-f059-4bc3-d8f3-9818e04ad02d"
      },
      "outputs": [],
      "source": [
        "layer1t = cp.tanh(cp.dot(xt, w_all.T))\n",
        "predt = cp.dot(layer1t,V)\n",
        "cp.corrcoef(predt,yt)[0,1]"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "jS-_e1vnqDTm"
      },
      "source": [
        "## Comparison"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Pko2WF88met6",
        "outputId": "38f3373e-3295-4b62-f6ae-7915dcdedcb8"
      },
      "outputs": [],
      "source": [
        "print(f\"NumPy/CuPy Time - Inner Layer: {numpy_time_inner/cupy_time_inner:.6f}\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "a55clruhqMpu",
        "outputId": "2a1e658b-fa04-42c0-af68-51c880e0c01f"
      },
      "outputs": [],
      "source": [
        "print(f\"NumPy/CuPy Time - Output Layer: {numpy_time_outer/cupy_time_outer:.6f}\")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "bjoaYPMBcsef"
      },
      "source": [
        "### Conclusions\n",
        "\n",
        "- **Matrix Multiplication Performance:** CuPy significantly outperforms NumPy in matrix multiplication, leveraging GPU parallelism for faster computations.\n",
        "- **Element-wise Operations:** For large arrays, CuPy is much faster than NumPy due to efficient parallel processing and higher memory bandwidth of GPUs.\n",
        "- **Batch Processing Efficiency:** CuPy handles large batches more effectively, fully utilizing GPU capabilities and reducing overhead, but batch sizes must be within available GPU RAM to avoid memory overflow.\n",
        "- **Optimization Strategy:** For handling larger data sizes exceeding GPU memory, use MPI to distribute computations across multiple GPUs or nodes for better performance and efficiency."
      ]
    }
  ],
  "metadata": {
    "accelerator": "GPU",
    "colab": {
      "gpuType": "T4",
      "provenance": [],
      "toc_visible": true
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}
